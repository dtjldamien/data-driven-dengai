{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "rng = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of dataset, with data preprocessing\n",
    "train_features = pd.read_csv('./data/train_features_modified.csv')\n",
    "train_labels = pd.read_csv('./data/dengue_labels_train.csv')\n",
    "test_features = pd.read_csv('./data/test_features_modified.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice train_features, test_features and train_labels by city\n",
    "# Seperate data for San Juan\n",
    "sj_train_features = train_features[train_features['city'] == 'sj']\n",
    "sj_train_labels = train_labels[train_labels['city'] == 'sj']\n",
    "\n",
    "sj_test_features = test_features[test_features['city'] == 'sj']\n",
    "\n",
    "# Separate data for Iquitos\n",
    "iq_train_features = train_features[train_features['city'] == 'iq']\n",
    "iq_train_labels = train_labels[train_labels['city'] == 'iq']\n",
    "\n",
    "iq_test_features = test_features[test_features['city'] == 'iq']\n",
    "\n",
    "# drop city and week_start_date columns from train_features and test_features as they are strings\n",
    "sj_train_features.drop(['city', 'week_start_date'], axis=1, inplace=True)\n",
    "sj_test_features.drop(['city', 'week_start_date'], axis=1, inplace=True)\n",
    "\n",
    "iq_train_features.drop(['city', 'week_start_date'], axis=1, inplace=True)\n",
    "iq_test_features.drop(['city', 'week_start_date'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters to 5\n",
    "kmeans_sj = KMeans(random_state=rng, n_clusters=5).fit(sj_train_features)\n",
    "clusters_sj = kmeans_sj.predict(sj_train_features)\n",
    "clusters_sj_test = kmeans_sj.predict(sj_test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters to 5\n",
    "kmeans_iq = KMeans(random_state=rng, n_clusters=5).fit(iq_train_features)\n",
    "clusters_iq = kmeans_iq.predict(iq_train_features)\n",
    "clusters_iq_test = kmeans_iq.predict(iq_test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a cluster column in order to split the data by cluster\n",
    "sj_train_features['cluster'] = clusters_sj\n",
    "sj_train_labels['cluster'] = clusters_sj\n",
    "sj_test_features['cluster'] = clusters_sj_test\n",
    "\n",
    "iq_train_features['cluster'] = clusters_iq\n",
    "iq_train_labels['cluster'] = clusters_iq\n",
    "iq_test_features['cluster'] = clusters_iq_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building regression models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageRegressor(BaseEstimator):\n",
    "    def __init__(self, regressors):\n",
    "        self.regressors = regressors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for regressor in self.regressors:\n",
    "            regressor.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([regressor.predict(X)\n",
    "                               for regressor in self.regressors]).T\n",
    "        return np.mean(predictions, axis=1)\n",
    "\n",
    "    def score(self, X):\n",
    "        return np.mean([regressor.score(X) for regressor in self.regressors])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regressors(X, y):\n",
    "    reg1 = GradientBoostingRegressor(random_state=rng)\n",
    "    reg2 = RandomForestRegressor(random_state=rng)\n",
    "    reg3 = AdaBoostRegressor(random_state=rng)\n",
    "\n",
    "    return [reg1, reg2, reg3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_models(train_features, train_labels):\n",
    "    best_regressors = []\n",
    "    for i in train_features['cluster'].unique():\n",
    "        train_features_cluster = train_features[train_features['cluster'] == i]\n",
    "        train_labels_cluster = train_labels[train_labels['cluster'] == i]\n",
    "\n",
    "        regressors = get_regressors(\n",
    "            train_features_cluster, train_labels_cluster)\n",
    "        avg_reg = AverageRegressor(regressors)\n",
    "\n",
    "        # build pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('scalar', StandardScaler(with_mean=False)),\n",
    "            ('selectkbest', SelectKBest()),\n",
    "            ('avg_regressor', avg_reg)\n",
    "        ])\n",
    "\n",
    "        # hyperparameter tuning\n",
    "        hyperparameters = {\n",
    "            'selectkbest__k': np.arange(20, 80, 10),\n",
    "            # skipped hyperparameter tuning for avg_regressor because it requires too much compute power to run\n",
    "            # 'avg_regressor__randomforestregressor__max_depth': np.arange(1, 10),\n",
    "            # 'avg_regressor__randomforestregressor__n_estimators': np.arange(1, 100, 10),\n",
    "        }\n",
    "\n",
    "        estimator = GridSearchCV(pipeline, hyperparameters, cv=5)\n",
    "        estimator.fit(train_features_cluster,\n",
    "                      train_labels_cluster['total_cases'])\n",
    "\n",
    "        best_regressors.append(estimator.best_estimator_)\n",
    "    return best_regressors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_regression_models = get_regression_models(\n",
    "    sj_train_features, sj_train_labels)\n",
    "iq_regression_models = get_regression_models(\n",
    "    iq_train_features, iq_train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_predictions = []\n",
    "\n",
    "# iterating each row of the test data and keeping track of the prediction for each row\n",
    "# while using the different regression models for prediction based on their cluster\n",
    "for index, row in sj_test_features.iterrows():\n",
    "    cluster = row['cluster'].astype(int)\n",
    "    pred = sj_regression_models[cluster].predict(row.values.reshape(1, -1))[0]\n",
    "    sj_predictions.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_predictions = []\n",
    "\n",
    "# iterating each row of the test data and keeping track of the prediction for each row\n",
    "# while using the different regression models for prediction based on their cluster\n",
    "for index, row in iq_test_features.iterrows():\n",
    "    cluster = row['cluster'].astype(int)\n",
    "    pred = iq_regression_models[cluster].predict(row.values.reshape(1, -1))[0]\n",
    "    iq_predictions.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sj_predictions + iq_predictions\n",
    "predictions = np.array(predictions, dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"./data/submission_format.csv\", index_col=[0, 1, 2])\n",
    "submission.total_cases = predictions\n",
    "submission.to_csv(\"./output/approach_4.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01fc90053a029df74eb881ecb0a44758ccef8ed513a488e06f5efd3ab0592068"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
