{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "rng = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of dataset, with data preprocessing\n",
    "train_features = pd.read_csv('./data/train_features_modified.csv')\n",
    "train_labels = pd.read_csv('./data/dengue_labels_train.csv')\n",
    "test_features = pd.read_csv('./data/test_features_modified.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice train_features, test_features and train_labels by city\n",
    "# Seperate data for San Juan\n",
    "sj_train_features = train_features[train_features['city'] == 'sj']\n",
    "sj_train_labels = train_labels[train_labels['city']\n",
    "                               == 'sj']['total_cases'].values.reshape(-1, 1)\n",
    "sj_test_features = test_features[test_features['city'] == 'sj']\n",
    "\n",
    "# Separate data for Iquitos\n",
    "iq_train_features = train_features[train_features['city'] == 'iq']\n",
    "iq_train_labels = train_labels[train_labels['city']\n",
    "                               == 'iq']['total_cases'].values.reshape(-1, 1)\n",
    "iq_test_features = test_features[test_features['city'] == 'iq']\n",
    "\n",
    "# drop city column from train_features and test_features\n",
    "sj_train_features.drop(['city', 'week_start_date'], axis=1, inplace=True)\n",
    "sj_test_features.drop(['city', 'week_start_date'], axis=1, inplace=True)\n",
    "\n",
    "iq_train_features.drop(['city', 'week_start_date'], axis=1, inplace=True)\n",
    "iq_test_features.drop(['city', 'week_start_date'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_sj = KMeans(random_state=rng).fit(sj_train_features)\n",
    "clusters_sj = kmeans_sj.predict(sj_train_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_iq = KMeans(random_state=rng).fit(iq_train_features)\n",
    "clusters_iq = kmeans_iq.predict(iq_train_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after using kmeans -> use clustering to find the subset of data to train each classifier, then have an average classifier\n",
    "# then use ensemble to combine the classifiers\n",
    "# no need to cluster for test data\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01fc90053a029df74eb881ecb0a44758ccef8ed513a488e06f5efd3ab0592068"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('is4242': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
